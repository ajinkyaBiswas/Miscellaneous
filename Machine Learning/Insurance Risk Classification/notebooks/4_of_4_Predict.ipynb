{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Python Imports \n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import math, random, datetime\n",
    "# Data Manipulation \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt \n",
    "import missingno \n",
    "import seaborn as sns \n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_70 = pd.read_csv('../final_data/F70_train.csv')\n",
    "list_70_features = list(df_70.columns)\n",
    "list_70_features.remove('Response')\n",
    "\n",
    "df_40 = pd.read_csv('../final_data/F40.csv')\n",
    "list_40_features = list(df_40.columns)\n",
    "list_40_features.remove('Response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hold out set processed\n",
      "raw test set processed\n",
      "test sets have been put into dictionary\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# prepare out test sets for prediction\n",
    "df_hold_out = pd.read_csv('../final_data/F70_test.csv') \n",
    "\n",
    "#df_X_test_hold_out_70 = df_hold_out[list_70_features]\n",
    "#df_X_test_hold_out_40 = df_hold_out[list_40_features]\n",
    "\n",
    "# this will be used to get actual/real performance on holdout set\n",
    "df_y_test_hold_out = df_hold_out[['Response']]\n",
    "\n",
    "print('hold out set processed')\n",
    "\n",
    "\n",
    "# prepare raw_test_70 and raw_test_40\n",
    "df_raw_test = pd.read_csv('../raw_data/test.csv')\n",
    "\n",
    "# 1. intruduce medical_keyword_sum \n",
    "# 2. encode product_info_2\n",
    "# 3. impute\n",
    "# 4. Only take features that we need..this way we don't have to do selective drop of features\n",
    "\n",
    "df_raw_test['Medical_Keyword_SUM'] = df_raw_test.loc[:, 'Medical_Keyword_1':'Medical_Keyword_48'].sum(axis = 1, skipna = True)\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Product_Info_2 = df_raw_test['Product_Info_2']\n",
    "Product_Info_2_encoded = encoder.fit_transform(Product_Info_2)\n",
    "\n",
    "# let's add this array to dataframe...\n",
    "df_raw_test['Product_Info_2_encoded'] = Product_Info_2_encoded\n",
    "\n",
    "# Impute..categorical variables with mode...cont var with mean\n",
    "df_raw_test['Medical_History_1'].fillna(df_raw_test['Medical_History_1'].mode()[0], inplace=True)\n",
    "df_raw_test.fillna(df_raw_test.mean(), inplace=True)\n",
    "\n",
    "#df_X_test_raw_70 = df_raw_test[list_70_features]\n",
    "#df_X_test_raw_40 = df_raw_test[list_40_features]\n",
    "\n",
    "print('raw test set processed')\n",
    "\n",
    "dict_test_sets = {'hold_out_70':df_hold_out, 'hold_out_40':df_hold_out,\\\n",
    "                  'raw_test_70':df_raw_test, 'raw_test_40':df_raw_test}\n",
    "\n",
    "print('test sets have been put into dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# create best models from our analysis\n",
    "model_log = LogisticRegression(C=10000.0, penalty='l2', random_state=0)\n",
    "model_svc = SVC(C=2.782559402207126, cache_size=200, class_weight=None, coef0=0.0,\\\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.005623413251903491,\\\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\\\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "dict_models = {'logistic': model_log, 'SVC': model_svc}\n",
    "\n",
    "# we have 4 training sets - F70, F40, B70, B40 for each model and 4 test(2 from holdout and 2 from raw test sets)\n",
    "dict_training_sets = {'F70':pd.read_csv('../final_data/F70_train.csv'), 'F40':pd.read_csv('../final_data/F40.csv'), \\\n",
    "                      'B70':pd.read_csv('../final_data/B70.csv'), 'B40':pd.read_csv('../final_data/B40.csv')}\n",
    "\n",
    "\n",
    "# we will use values from dictionaries to process...and log the keys into list of dictionaries...\n",
    "# later we will convert list_all_results to a dataframe to get a complete overview\n",
    "list_all_results = []\n",
    "\n",
    "for m in dict_models:\n",
    "    scaled = m == 'SVC'\n",
    "    model = dict_models[m]\n",
    "    for train in dict_training_sets:\n",
    "        result = {}\n",
    "        result['model'] = m\n",
    "        result['training_set'] = train\n",
    "        features = list(dict_training_sets[train].columns)\n",
    "        features.remove('Response')\n",
    "        num_features = '70' if '70' in train else '40'\n",
    "        train_X = dict_training_sets[train][features]\n",
    "        if scaled:\n",
    "            train_X = preprocessing.scale(train_X)\n",
    "        train_y = dict_training_sets[train][['Response']]\n",
    "        model.fit(train_X, train_y)\n",
    "        score = cross_val_score(model, train_X, train_y, cv=StratifiedKFold(3), n_jobs=3)\n",
    "        result['cross_val_score'] = sum(score) / len(score)\n",
    "        for test in dict_test_sets:\n",
    "            if num_features not in test:\n",
    "                continue\n",
    "            #result['test_set'] = test\n",
    "            test_X = dict_test_sets[test][features]\n",
    "            if scaled:\n",
    "                test_X = preprocessing.scale(test_X)\n",
    "            pred_result = model.predict(test_X)\n",
    "            output = pd.concat([dict_test_sets[test], pd.DataFrame({'Response':pred_result})], axis=1, sort=False)\n",
    "            fileName = f'{m}_{train}_{test}_result.csv'\n",
    "            output.to_csv(f'../partial_data/{fileName}', index=False)\n",
    "            #result['generated_file'] = fileName\n",
    "        list_all_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>training_set</th>\n",
       "      <th>cross_val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>F70</td>\n",
       "      <td>0.466024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>F40</td>\n",
       "      <td>0.462908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic</td>\n",
       "      <td>B70</td>\n",
       "      <td>0.369290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic</td>\n",
       "      <td>B40</td>\n",
       "      <td>0.367747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>F70</td>\n",
       "      <td>0.492443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model training_set  cross_val_score\n",
       "0  logistic          F70         0.466024\n",
       "1  logistic          F40         0.462908\n",
       "2  logistic          B70         0.369290\n",
       "3  logistic          B40         0.367747\n",
       "4       SVC          F70         0.492443"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert list_all_results to a dataframe to get a complete overview\n",
    "pd.DataFrame(list_all_results).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of logistic_B40_hold_out_40_result.csv: 0.39302854256125286\n",
      "Score of logistic_B70_hold_out_70_result.csv: 0.39353372063652436\n",
      "Score of logistic_F40_hold_out_40_result.csv: 0.4643428475204176\n",
      "Score of logistic_F70_hold_out_70_result.csv: 0.46703713058853247\n",
      "Score of SVC_B40_hold_out_40_result.csv: 0.3587606297886672\n",
      "Score of SVC_B70_hold_out_70_result.csv: 0.3583396480592742\n",
      "Score of SVC_F40_hold_out_40_result.csv: 0.49355897954028793\n",
      "Score of SVC_F70_hold_out_70_result.csv: 0.4954112991496169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# check our performance on hold-out sets...\n",
    "#test_data = pd.read_csv(f'../final_data/F70_test.csv')\n",
    "#y_test = test_data[['Response']]\n",
    "\n",
    "filenames = ['logistic_B40_hold_out_40_result.csv',\n",
    "            'logistic_B70_hold_out_70_result.csv',\n",
    "            'logistic_F40_hold_out_40_result.csv',\n",
    "            'logistic_F70_hold_out_70_result.csv',\n",
    "            'SVC_B40_hold_out_40_result.csv',\n",
    "            'SVC_B70_hold_out_70_result.csv',\n",
    "            'SVC_F40_hold_out_40_result.csv',\n",
    "            'SVC_F70_hold_out_70_result.csv']\n",
    "for filename in filenames:\n",
    "    if 'hold_out' not in filename:\n",
    "        continue\n",
    "    result_data = pd.read_csv(f'../partial_data/{filename}')\n",
    "\n",
    "    y_test = result_data[['Response']]\n",
    "    y_result = result_data.iloc[:,-1]\n",
    "\n",
    "    score = accuracy_score(y_test, y_result)\n",
    "    print(f'Score of {filename}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the cross val scores and performance on hold-out sets, we choose to submit....\n",
    "test_data = pd.read_csv(f'../raw_data/test.csv')\n",
    "result_data = pd.read_csv(f'../partial_data/logistic_F70_raw_test_70_result.csv')\n",
    "\n",
    "output = pd.concat([test_data[['Id']], result_data[['Response']]], axis=1, sort=False)\n",
    "output.to_csv('../results/submission_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
